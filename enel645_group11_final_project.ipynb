{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Import libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "source": [
    "## Prepare and explore data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "input_dir = 'Development/Screenshots'\n",
    "target_dir = 'Development/ScreenshotMasks'\n",
    "img_size = (480, 640)\n",
    "batch_size = 16\n",
    "\n",
    "input_img_paths = sorted(\n",
    "    [\n",
    "        os.path.join(input_dir, fname)\n",
    "        for fname in os.listdir(input_dir)\n",
    "        if fname.endswith('.png')\n",
    "    ]\n",
    ")\n",
    "target_img_paths = sorted(\n",
    "    [\n",
    "        os.path.join(target_dir, fname)\n",
    "        for fname in os.listdir(target_dir)\n",
    "        if fname.endswith('.txt')\n",
    "    ]\n",
    ")\n",
    "\n",
    "if (len(input_img_paths) != len(target_img_paths)):\n",
    "    raise Exception('dataset error')\n",
    "\n",
    "num_samples = len(input_img_paths)\n",
    "print('Number of samples:', num_samples)\n",
    "\n",
    "classes = np.array([0])\n",
    "for mask_path in target_img_paths:\n",
    "    mask = np.loadtxt(mask_path)\n",
    "    classes = np.unique(np.concatenate((classes, np.unique(mask))))\n",
    "\n",
    "num_classes = len(classes)\n",
    "print('Number of classes:', num_classes)\n",
    "\n",
    "for input_path, target_path in zip(input_img_paths[:5], target_img_paths[:5]):\n",
    "    print(input_path, '|', target_path)\n",
    "\n",
    "\n",
    "# Shuffle the data\n",
    "indexes = np.arange(len(input_img_paths), dtype = int)\n",
    "np.random.shuffle(indexes)\n",
    "\n",
    "input_img_paths = [input_img_paths[i] for i in indexes]\n",
    "target_img_paths = [target_img_paths[i] for i in indexes]\n",
    "\n",
    "print('After shuffle: ')\n",
    "\n",
    "for input_path, target_path in zip(input_img_paths[:5], target_img_paths[:5]):\n",
    "    print(input_path, '|', target_path)"
   ]
  },
  {
   "source": [
    "## Revise pixel-wise labels"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converters = {\n",
    "#     0: 0, # Background\n",
    "\n",
    "#     1: 1, # Field\n",
    "\n",
    "#     2: 2, # Lines\n",
    "\n",
    "#     3: 3, # Ball\n",
    "\n",
    "#     4: 4, # Robots\n",
    "#     5: 4, # Robots\n",
    "#     6: 4, # Robots\n",
    "#     7: 4, # Robots\n",
    "#     8: 4, # Robots\n",
    "#     9: 4, # Robots\n",
    "#     10: 4, # Robots\n",
    "#     11: 4, # Robots\n",
    "#     12: 4, # Robots\n",
    "\n",
    "#     13: 5, # Goals\n",
    "#     14: 5  # Goals\n",
    "# }\n",
    "\n",
    "def read_mask(path):\n",
    "    mask = np.loadtxt(path)\n",
    "    # for key in converters.keys():\n",
    "    #     mask[mask==key] = converters[key]\n",
    "    return mask"
   ]
  },
  {
   "source": [
    "## Display the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 10), dpi=300)\n",
    "for i in range(2):\n",
    "    img = plt.imread(input_img_paths[i])\n",
    "    plt.subplot(1, 4, i*2+1)\n",
    "    plt.imshow(img/img.max())\n",
    "    plt.axis('off')\n",
    "    plt.title('Image')\n",
    "    plt.subplot(1, 4, i*2+2)\n",
    "    mask = read_mask(target_img_paths[i])\n",
    "    plt.imshow(mask/mask.max(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title('Mask')\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## Create helper to iterete over the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "class RoboCup(tf.keras.utils.Sequence):\n",
    "    \"\"\"Helper to iterate over the data (as Numpy arrays).\"\"\"\n",
    "\n",
    "    def __init__(self, batch_size, img_size, input_img_paths, target_img_paths):\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.input_img_paths = input_img_paths\n",
    "        self.target_img_paths = target_img_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_img_paths) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n",
    "        i = idx * self.batch_size\n",
    "        batch_input_img_paths = self.input_img_paths[i : i + self.batch_size]\n",
    "        batch_target_img_paths = self.target_img_paths[i : i + self.batch_size]\n",
    "        x = np.zeros((self.batch_size,) + self.img_size + (3,), dtype=\"float32\")\n",
    "        for j, path in enumerate(batch_input_img_paths):\n",
    "            # img = plt.imread(path)\n",
    "            img = load_img(path, target_size=self.img_size)\n",
    "            x[j] = img\n",
    "        y = np.zeros((self.batch_size,) + self.img_size + (1,), dtype=\"uint8\")\n",
    "        for j, path in enumerate(batch_target_img_paths):\n",
    "            img = read_mask(path)\n",
    "            y[j] = np.expand_dims(img, 2)\n",
    "        return x, y\n"
   ]
  },
  {
   "source": [
    "## Define the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet_mod(num_classes, img_size = (640, 480), learning_rate = 1e-3,\\\n",
    "                 learning_decay = 1e-6, drop_out = 0.1, nchannels = 3,kshape = (3,3)):\n",
    "    ''' Get U-Net model with gaussian noise and dropout'''\n",
    "    \n",
    "    inputs = tf.keras.Input(shape=img_size + (nchannels,))\n",
    "\n",
    "    ### [First half of the network: downsampling inputs] ###\n",
    "\n",
    "    # Entry block\n",
    "    x = tf.keras.layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
    "    for filters in [64, 128, 256]:\n",
    "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "        x = tf.keras.layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "        x = tf.keras.layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "        x = tf.keras.layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = tf.keras.layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = tf.keras.layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    ### [Second half of the network: upsampling inputs] ###\n",
    "\n",
    "    for filters in [256, 128, 64, 32]:\n",
    "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "        x = tf.keras.layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "        x = tf.keras.layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "        x = tf.keras.layers.UpSampling2D(2)(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = tf.keras.layers.UpSampling2D(2)(previous_block_activation)\n",
    "        residual = tf.keras.layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
    "        x = tf.keras.layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    # Add a per-pixel classification layer\n",
    "    outputs = tf.keras.layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n",
    "\n",
    "    # Define the model\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    opt = tf.keras.optimizers.Adam(lr= learning_rate, decay = learning_decay)\n",
    "    model.compile(optimizer=opt, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Build model\n",
    "model = get_unet_mod(num_classes, img_size)\n",
    "model.summary()"
   ]
  },
  {
   "source": [
    "## Split data into train / validation / test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Split our img paths into a training and a validation set\n",
    "val_samples = int(0.15 * num_samples)\n",
    "test_samples = int(0.15 * num_samples)\n",
    "train_samples = num_samples - val_samples - test_samples\n",
    "\n",
    "train_input_img_paths = input_img_paths[:train_samples]\n",
    "train_target_img_paths = target_img_paths[:train_samples]\n",
    "\n",
    "val_input_img_paths = input_img_paths[train_samples:train_samples + val_samples]\n",
    "val_target_img_paths = target_img_paths[train_samples:train_samples + val_samples]\n",
    "\n",
    "test_input_img_paths = input_img_paths[train_samples + val_samples:train_samples + val_samples + test_samples]\n",
    "test_target_img_paths = target_img_paths[train_samples + val_samples:train_samples + val_samples + test_samples]\n",
    "\n",
    "# Instantiate data Sequences for each split\n",
    "train_gen = RoboCup(batch_size, img_size, train_input_img_paths, train_target_img_paths)\n",
    "val_gen = RoboCup(batch_size, img_size, val_input_img_paths, val_target_img_paths)\n",
    "test_gen = RoboCup(batch_size, img_size, test_input_img_paths, test_target_img_paths)"
   ]
  },
  {
   "source": [
    "## Define callbacks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the model for training.\n",
    "# We use the \"sparse\" version of categorical_crossentropy\n",
    "# because our target data is integers.\n",
    "\n",
    "model_name = \"unet_seg.h5\"\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 20)\n",
    "\n",
    "monitor = tf.keras.callbacks.ModelCheckpoint(model_name, monitor='val_loss',\\\n",
    "                                             verbose=0,save_best_only=True,\\\n",
    "                                             save_weights_only=True,\\\n",
    "                                             mode='min')\n",
    "# Learning rate schedule\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch%3 == 0 and epoch!= 0:\n",
    "        lr = lr/2\n",
    "    return lr\n",
    "\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(scheduler,verbose = 0)\n",
    "\n",
    "callbacks = [early_stop, monitor, lr_schedule]"
   ]
  },
  {
   "source": [
    "## Train the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model, doing validation at the end of each epoch.\n",
    "epochs = 3\n",
    "model.fit(train_gen, epochs=epochs, validation_data=(val_gen,), callbacks=callbacks)"
   ]
  },
  {
   "source": [
    "## Visualize test results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = model.predict(test_gen)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,18), dpi=300)\n",
    "for i in range(2):\n",
    "    img = plt.imread(val_input_img_paths[i])\n",
    "    plt.subplot(2, 3, i*3+1)\n",
    "    plt.imshow(img/img.max())\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Image\")\n",
    "    plt.subplot(2, 3, i*3+2)\n",
    "    predicted_mask = np.argmax(val_preds[i], axis=-1)\n",
    "    predicted_mask = np.expand_dims(predicted_mask, axis=-1)\n",
    "    plt.imshow(predicted_mask/predicted_mask.max(), cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Predicted Mask\")\n",
    "    plt.subplot(2, 3, i*3+3)\n",
    "    actual_mask = read_mask(val_target_img_paths[i])\n",
    "    plt.imshow(actual_mask/actual_mask.max(), cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Actual Mask\")\n",
    "plt.show()"
   ]
  }
 ]
}